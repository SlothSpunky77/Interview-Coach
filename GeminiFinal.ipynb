{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9OEoeosRTv-5",
    "outputId": "d5bd364a-09f1-4417-e2f7-ae3f436aeb10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\user\\anaconda3\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
      "Requirement already satisfied: pyaudio in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\user\\anaconda3\\lib\\site-packages (2.90)\n",
      "Requirement already satisfied: comtypes in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyttsx3) (1.3.1)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Requirement already satisfied: vadersentiment in c:\\users\\user\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from vadersentiment) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->vadersentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->vadersentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->vadersentiment) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->vadersentiment) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-generativeai\n",
    "!pip install SpeechRecognition\n",
    "!pip install pyaudio\n",
    "!pip install pyttsx3\n",
    "!pip install vadersentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adehnPZ_tnwi"
   },
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vQWVUgQ_ttJ5"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ab9ASynfcIZn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getenv('API_KEY')\n",
    "\n",
    "genai.configure(api_key=\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "QvvWFy08e5c5",
    "outputId": "328d9581-03f2-4f52-f03c-37fea5fbaf50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2bcfnGEviwTI"
   },
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_questions=[\n",
    "    [\"\"\"Why do you want to work in retail?\"\"\"\n",
    "     ,\n",
    "     \"\"\"(Most Favorable): I enjoy interacting with people and helping them find what they need. I'm passionate about [company's product/service] and believe in its value to customers. I'm a team player and thrive in a fast-paced environment. (This answer shows enthusiasm, product knowledge, and teamwork skills.)\n",
    "    (Favorable): I'm looking for a customer-facing role to develop my communication and sales skills. I believe retail offers a dynamic work environment and opportunities for growth. (This answer highlights a desire for skill development and a willingness to learn.)\n",
    "    (Neutral): I need a job, and retail seems like a good starting point.(This answer is neutral, but doesn't show specific interest in the role.)\n",
    "    (Less Favorable): My previous job wasn't a good fit, and I'm open to different opportunities. (This focuses on the negative aspects of a past job.)\n",
    "    (Least Favorable): The hours work well with my schedule.(This answer only focuses on personal needs, not the company or role.)\n",
    "    \"\"\"\n",
    "    ],\n",
    "    [\"\"\"How would you handle a difficult customer?\"\"\"\n",
    "     ,\n",
    "     \"\"\"(Most Favorable): \"I would stay calm, listen actively to understand their concerns, and apologize for any inconvenience. I would then try to find a solution that meets their needs. If necessary, I would escalate the situation to a manager while remaining courteous to the customer.\" (This answer emphasizes active listening, problem-solving, and maintaining composure under pressure.)\n",
    "    (Favorable): \"I would try to empathize with the customer's frustration and offer solutions or alternatives. I would also be professional and respectful in my communication.\" (This answer focuses on empathy, communication skills, and de-escalation.)\n",
    "    (Neutral): \"I would try to reason with the customer and explain the store policy.\" (This answer suggests a more confrontational approach.)\n",
    "    (Less Favorable): \"I would avoid getting into an argument and just let them vent.\" (This answer shows a passive approach to conflict resolution.)\n",
    "    (Least Favorable): \"I would ask a coworker to deal with them.\" (This answer avoids taking responsibility.)\n",
    "    \"\"\"\n",
    "    ],\n",
    "    [\"\"\"You're due to leave at 5 pm but your replacement worker doesn't show up. What would you do?\"\"\"\n",
    "     ,\n",
    "     \"\"\"(Most Favorable):\"I would first try to contact my replacement to see if they are running late or unable to make their shift. If I can't reach them, I would inform my manager immediately and explain the situation. I would then offer to stay until they can find someone to cover the remaining time, or until a reasonable handover can occur to another coworker. My priority would be to ensure smooth store operations and minimize any inconvenience to customers or colleagues.\" (This answer shows initiative, responsibility, and teamwork.)\n",
    "    (Favorable): \"I would let my manager know as soon as possible that my replacement isn't there. I would then offer to stay for a short period to help out, but would explain that I have commitments and cannot stay indefinitely.\" (This answer emphasizes communication and willingness to help, but also sets boundaries.)\n",
    "    (Neutral): \"I would clock out at 5 pm as scheduled.\" (This answer is neutral, but doesn't show a strong commitment to the team or customer service.)\n",
    "    (Less Favorable): \"I would leave a note for my replacement and clock out at 5 pm.\" (This answer lacks communication and doesn't ensure a smooth handover.)\n",
    "    (Least Favorable): \"I would just leave without saying anything.\" (This answer is unprofessional and irresponsible.)\n",
    "    \"\"\"\n",
    "    ],\n",
    "    [\"\"\"A customer wants to return some goods that have been clearly opened and used. How would you handle it?\"\"\"\n",
    "     ,\n",
    "     \"\"\"(Most Favorable): \"I would politely greet the customer and ask for their receipt. I would then explain the store's return policy regarding opened or used items. If the policy allows for a partial refund or exchange, I would explain those options clearly and professionally. I would also offer to see if there's anything else I can help them with.\" (This answer demonstrates knowledge of policy, clear communication, and customer service focus.)\n",
    "    (Favorable): \"I would apologize for any inconvenience and ask the customer to see the product. I would then explain the store's return policy and try to find a solution that works for them, such as an exchange for a different item or store credit, if allowed by the policy.\" (This answer prioritizes customer satisfaction while adhering to policy.)\n",
    "    (Neutral): \"I would ask the customer for their receipt and explain the store's return policy.\" (This answer is neutral, but lacks details on how you'd handle the specific situation.)\n",
    "    (Less Favorable): \"I would inform the customer that the item cannot be returned because it's opened.\" (This answer lacks clear explanation and could lead to customer dissatisfaction.)\n",
    "    (Least Favorable): \"That's not possible, you can't return a used item.\" (This answer is confrontational and offers no solution to the customer.)\n",
    "    \"\"\"\n",
    "    ],\n",
    "    [\"\"\"How do you handle rejection after a customer declines to purchase a product so that you can do better when a new customer arrives?\"\"\"\n",
    "     ,\n",
    "     \"\"\"(Most Favorable): \"Thank the customer for their time and consideration. Briefly ask if there was anything about the product that didn't meet their needs. This can provide valuable insights for future interactions. Then, politely excuse yourself and move on to the next customer with a positive attitude, focusing on how you can help them.\" (This answer shows appreciation, seeks feedback for improvement, and maintains a professional demeanor.)\n",
    "\n",
    "    (Favorable): \"Acknowledge the customer's decision and offer assistance with finding alternative products that might better suit their needs. This demonstrates a willingness to help and showcases your product knowledge.\" (This answer focuses on customer service and suggests alternative solutions.)\n",
    "    (Neutral): \"Thank the customer for their time.\" (This answer is neutral, but lacks the initiative to learn or improve future interactions.)\n",
    "    (Less Favorable): \"No problem, maybe next time.\" (This answer shows a lack of enthusiasm and doesn't attempt to learn from the interaction.)\n",
    "    (Least Favorable): \"That's a shame, you're missing out on a great product.\" (This answer is dismissive and could come across as pressuring the customer.)\n",
    "    \"\"\"\n",
    "    ]\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "def TTS(msg):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', 150)  \n",
    "\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[0].id)  \n",
    "\n",
    "    text = msg\n",
    "\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak Anything...\n",
      "Speak Anything...\n",
      "Speak Anything...\n",
      "Speech Recognition could not understand audio\n",
      "Speak Anything...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mMicrophone() \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeak Anything...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m     audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mlisten(source)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Recognize speech using Google Speech Recognition \u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\speech_recognition\\__init__.py:491\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 491\u001b[0m buffer \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mread(source\u001b[38;5;241m.\u001b[39mCHUNK)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    493\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyaudio_stream\u001b[38;5;241m.\u001b[39mread(size, exception_on_overflow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mread_stream(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!pip install speech_recognition\n",
    "import speech_recognition as sr\n",
    "#pair=interview_questions[0]\n",
    "#question= pair[0]\n",
    "\n",
    "sentiment = []\n",
    "finalFeedback = []\n",
    "\n",
    "for question, answer in interview_questions:\n",
    "    TTS(question)\n",
    "    # Record audio using microphone\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Speak Anything...\")\n",
    "        audio = recognizer.listen(source)\n",
    "    \n",
    "    # Recognize speech using Google Speech Recognition \n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "       # print(\"You said: {}\".format(text))\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Speech Recognition could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "    \n",
    "    #answer=\"\"\" I enjoy interacting with people and helping them find what they need. I'm passionate about the company's work ethic and believe in its value to customers. I'm a team player and thrive in a fast-paced environment.\"\"\"\n",
    "    feedback=model.generate_content(question+\"Actual answer : \"+ answer +\"\\n Users answer : \"+text+\n",
    "                                    \"\\n Can you compare the actual answer and the users answer and give feedback in 30 words or less and assign a rating to the answer the user has given on a scale of 1 to 10 .\")\n",
    "    message=feedback.text\n",
    "    finalFeedback.append(message)\n",
    "    TTS(message)\n",
    "\n",
    "    prompt1 = f\"\"\"You are an expert at classifying text into either positive, negative or neutral. \n",
    "    For every text input that you get, you are to classify it into either positive, neutral or negative.\n",
    "    The text input is provided between three backticks below.\n",
    "    ```\n",
    "    {text}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    response1 = model.generate_content(prompt1)\n",
    "    sentiment.append(response1.text)\n",
    "\n",
    "print(sentiment)\n",
    "prompt2 = f\"\"\"You have just finished interviewig a person from the retail industry, and these are all the feedbacks you have given\n",
    "            {finalFeedback[0]}\\n\n",
    "            {finalFeedback[1]}\\n\n",
    "            {finalFeedback[2]}\\n\n",
    "            {finalFeedback[3]}\\n\n",
    "            {finalFeedback[4]}\\n\n",
    "            Give a final feedback by summarising all the above feedbacks \"\"\"\n",
    "response2 = model.generate_content(prompt2)\n",
    "message2 = response2.text\n",
    "TTS(message2)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #answer=\"\"\" I enjoy interacting with people and helping them find what they need. I'm passionate about the company's work ethic and believe in its value to customers. I'm a team player and thrive in a fast-paced environment.\"\"\"\n",
    "# feedback=model.generate_content(question+\"Actual answer : \"+pair[1]+\"\\n Users answer : \"+text+\n",
    "#                                 \"\\n Can you compare the actual answer and the users answer and give feedback in 30 words or less and assign a rating to the answer the user has given on a scale of 1 to 10 .\")\n",
    "# message=feedback.text\n",
    "# TTS(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence=(str(text))\n",
    "analyser=SentimentIntensityAnalyzer()\n",
    "for i in Sentence:\n",
    "    v=analyser.polarity_scores(i)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!pip install speech_recognition\n",
    "# import speech_recognition as sr\n",
    "\n",
    "# # Record audio using microphone\n",
    "# recognizer = sr.Recognizer()\n",
    "# with sr.Microphone() as source:\n",
    "#     print(\"Speak Anything...\")\n",
    "#     audio = recognizer.listen(source)\n",
    "\n",
    "# # Recognize speech using Google Speech Recognition\n",
    "# try:\n",
    "#     text = recognizer.recognize_google(audio)\n",
    "#     print(\"You said: {}\".format(text))\n",
    "# except sr.UnknownValueError:\n",
    "#     print(\"Speech Recognition could not understand audio\")\n",
    "# except sr.RequestError as e:\n",
    "#     print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ibm_watson\n",
    "# import json\n",
    "# from ibm_watson import SpeechToTextV1\n",
    "# from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "# # Replace with your IBM Cloud IAM API key\n",
    "# iam_apikey = \"YOUR_API_KEY\"\n",
    "\n",
    "# # Replace with the URL for your Watson Speech to Text service\n",
    "# url = \"https://api.us-south.speech-to-text.watson.cloud.ibm.com/instances/YOUR_SERVICE_INSTANCE_ID\"\n",
    "\n",
    "# # Authenticate\n",
    "# authenticator = IAMAuthenticator(iam_apikey)\n",
    "# service = SpeechToTextV1(authenticator=authenticator)\n",
    "\n",
    "# # Function to recognize speech in real-time from a microphone recording\n",
    "# def recognize_from_microphone(stream):\n",
    "#   try:\n",
    "#     # Set up streaming recognition options\n",
    "#     recognize_request = SpeechRecognitionResults(service=service)\n",
    "#     settings = RecognitionSettings(\n",
    "#       continuous=True,\n",
    "#       interim_results=True,\n",
    "#       word_confidence=True\n",
    "#     )\n",
    "#     recognize_request.start(settings=settings, audio=stream)\n",
    "\n",
    "#     # Process the real-time transcription results\n",
    "#     for transcript in recognize_request.get_result():\n",
    "#       if transcript.get(\"results\"):\n",
    "#         for result in transcript[\"results\"]:\n",
    "#           alternatives = result.get(\"alternatives\", [])\n",
    "#           if alternatives:\n",
    "#             text = alternatives[0][\"transcript\"]\n",
    "#             confidence = alternatives[0][\"confidence\"]\n",
    "#             print(f\"You said: {text} (Confidence: {confidence:.2f})\")\n",
    "\n",
    "#     print(\"Speech recognition completed.\")\n",
    "#   except Exception as e:\n",
    "#     print(\"Error recognizing speech:\", e)\n",
    "\n",
    "# # Example usage\n",
    "# with sr.Microphone() as source:\n",
    "#   print(\"Speak now...\")\n",
    "#   recognize_from_microphone(source.stream())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "google": {
   "image_path": "/static/site-assets/images/docs/logo-python.svg",
   "keywords": [
    "examples",
    "gemini",
    "beginner",
    "googleai",
    "quickstart",
    "python",
    "text",
    "chat",
    "vision",
    "embed"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
